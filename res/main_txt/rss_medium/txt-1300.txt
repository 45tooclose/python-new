
Light Paper: Artificial Intelligence in HyperQuant EcosystemRisk management is pivotal when trading on the crypto-currency exchanges. The way you approach this vital task determines the lifespan of the utilized trading strategies.The use of Artificial Intelligence (AI) is the most prospective among the possible solutions. That is why we in HyperQuant heavily focus on revolutionary AI approaches.The combined decision is thus taken based on the results of the studies listed below. Let’s go through the main AI directions and methods that HyperQuant favours.Methods that incorporate expert knowledge and are taught on open and proprietary datasets in HyperQuant’s possession.Bayesian estimation of risk distribution.This is an estimator that minimizes the posterior expected value of a loss function. It also maximizes the posterior expectation of a utility function. An alternative way of formulating an estimator within Bayesian statistics is maximum a posteriori estimation.Full stack of actuarial methodology.Actuarial methods are used in insurance. This is a mix of economics-mathematical methods of salary calculation. These are based on the law of large numbers. The methods reflect the mechanism of insurance fund creation and utility is long-term insurance operations that are connected to the population’s lifespan. The goal is to determine the participation share of each insurant in the creation of the insurance fund, i.e. — the salary size. The methodology is based on using the theory of probability, demographics and long-term financial calculations. Insurance operations include the equivalence principle visible through the equality of financial liabilities between an insurer and an insurant.Graphical models.For example, a decision tree. This method of decision making support is based on the use of a tree-like graph. This “tree” is a model of decision making that incorporates potential consequences (the probability of or another event taking place), effectiveness and resource-consumption. In a business process this tree is comprised of a minimal amount of questions that should be answered with a “yes” or a “no”. By answering these questions in sequence — we arrive to the right choice. The methodological advantages of the decision tree lie in it structuring and systemizing the problem with the final verdict based on the logical conclusions.Gaussian systems for processes, multivariate functions and the objects of a sophisticated structure like a set of qualitative indicators.In probability theory and statistics, a Gaussian process is a stochastic process. The stochastic process is a collection of random variables indexed by time or space. In Gaussian process every finite collection of those random variables has a multivariate normal distribution. Thus every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.A machine-learning algorithm that involves a Gaussian process uses “lazy” learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data. The prediction is not just an estimate for that point, but also has uncertainty information — it is a one-dimensional Gaussian distribution (which is the marginal distribution at that point). For some kernel functions, matrix algebra can be used to calculate the predictions using the technique of kriging.Point processed kernel methods.In machine learning kernel methods are an algorithm class of model analysis. The mots known from them is the support vector method (SVM), It is a whole set of algorithms required for solving the tasks of classification and regression analysis. Based on the fact that object located in N-dimensional space belongs to one of the two classes, the SVM creates a hyperplane with N-1 dimension for all the objects to be in one of the two groups. The general aim of pattern analysis is in the search and study of general relationship types (for example, clusters, ranging, components, correlations and qualifications) in data sets. For many algorithms solving these tasks — the data in its raw form needs to be changed to the vector interpretation of objects with the help of user’s object map, At the same time — the cored methods only demand the core specified by the user — thus the similarity function for the couples of data points in the unprocessed form.Methods of deep networks learning for the work with categorical objects.Long Short-Term Memory based systems (LSTM).Long short-term memory is a variety of recurrent neural networks architecture.. LSTM-network is unique in the sense that with enough of network elements — it can complete any calculation that a regular computer can take on. For this a corresponding weight matrix is required — it can be considered a programme.Contrary to the traditional recurrent neural networks, TSTM is well-equipped for learning on the tasks of classification, processing and forecast of temporary lines in cases, when important events are divided with time lags of unidentified length and borders. A relative immunity to lengthy time lags gives LSTM and advantage in front of alternative recurrent neural networks, closed mark models and other sequential systems of this kind.Seq2seq for sets models.One of the most popular architectures in machine translations are the sequence to sequence (Seq2Seq) models. The models consist of two recurrent networks: the coder and the decoder. The coder creates the input of the entry word sequence. The gained input (the last exit and the value of network cell) are copied to the decoder. Through the received input the decoder tries to reassemble the initial word sequence. In the tasks of machine translation the input and output sequences are the sentences in different languages. In question and answer as well as dialogue systems — question and answer.Reinforcement learning methods for situations of unclear cost function.Learning with reinforcement — is one of methods of machine learning during which a test system is taught by interacting with a certain environment. From the cybernetics point of view — this one of the types of cybernetic environment. The environment response (and not a special system of reinforcement management as it happens when studying with a teacher) on the taken decision are the reinforcement signals.So this learning is a subtype of learning with a teacher, but the teacher is the environment or its model. It is also important to note that certain reinforcement rules are based on non-clear teachers, for example in cases of artificial neural environment, on the simultaneous activity of formal neurons —which is way this can be counted as teacher-less learning.Generative models for simulations and data hungry subtasks.The process of teaching a generative model is as following: a large amount of data from certain area (millions of images, sentences or sounds, etc.) is amassed and then the model is taught to generate this data by itself. Neural networks that are used for generative models possess much less parameters compared to the assembled data that they rely on. So to generalize the data — the models need to locate and effectively analyze the samples.It is important to consider the following factors. The decision on utilizing s certain method is taken only after the detailed analysis of its effectiveness. The models can further self-educate with the new market data arriving. There is a possibility of increasing model sensitivity by increasing the computing performance and analysis depth in case of shifting to the emergency mode when an attack is being suspected. The models have place for the experts to monitor and indicate insides regarding a specified market situation at the current moment. The methodology of direction data is unified for all types of modules and passed through the A/B tests. The architecture of the system: distributed nodes in the cloud — this allows to choose between the system reaction speed, the depth of the analysis and the cluster prize.HyperQuant’s frame of mind.We in HyperQuant have outstanding experience with the development and use of such complex systems. We keep on trying new methods, expanding the horizons with the cutting-edge ideas. We build our work on the methods of the IT giants, yet advance them even further for your merit.We will make sure to tell you more about how our technologies work and profit you in the next instalments of this article series.HyperQuant Social Media